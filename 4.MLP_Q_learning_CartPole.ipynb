{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neojoey/rl/blob/main/4.MLP_Q_learning_CartPole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_akU1Jda1UDi"
      },
      "outputs": [],
      "source": [
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "!pip install gymnasium stable-baselines3[extra] pyglet swig\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display"
      ],
      "metadata": {
        "id": "lfz8Ych21V5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a virtual display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video(video_folder=\"videos\"):\n",
        "    \"\"\"Helper function to display a video in Colab\"\"\"\n",
        "    list_files = [f for f in os.listdir(video_folder) if f.endswith(\".mp4\")]\n",
        "    if len(list_files) == 0:\n",
        "        print(f\"No video found in {video_folder}\")\n",
        "        return\n",
        "\n",
        "    mp4 = os.path.join(video_folder, list_files[0])\n",
        "    video = open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video).decode()\n",
        "\n",
        "    # Display the video\n",
        "    return HTML(data=f'''\n",
        "        <video alt=\"test\" autoplay controls style=\"height: 400px;\">\n",
        "            <source src=\"data:video/mp4;base64,{encoded}\" type=\"video/mp4\" />\n",
        "        </video>''')\n"
      ],
      "metadata": {
        "id": "wpJ4gIzo1q8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma=0.99 # 할인율\n",
        "eps=1.0\n",
        "eps_decay=0.9999\n",
        "eps_min=0.05\n",
        "n_episode=2000\n",
        "\n",
        "greedy_select=lambda x:np.random.choice(np.argwhere(x==np.max(x)).flatten())\n",
        "\n",
        "def build_network(): # 신경망 만들기(MLP)\n",
        "    mlp=Sequential()\n",
        "    mlp.add(Dense(32,input_dim=s_dim,activation='relu'))\n",
        "    mlp.add(Dense(32,activation='relu'))\n",
        "    mlp.add(Dense(a_dim,activation='linear'))\n",
        "    mlp.compile(loss='MSE',optimizer=Adam(learning_rate=0.01))\n",
        "    return mlp\n",
        "\n",
        "env=gym.make('CartPole-v1')\n",
        "s_dim=env.observation_space.shape[0] # 상태 공간 차원\n",
        "a_dim=env.action_space.n # 행동 공간 차원\n",
        "\n",
        "model=build_network() # 신경망 생성"
      ],
      "metadata": {
        "id": "1nM8m_pP1-KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epi_length=[] # 에피소드의 길이\n",
        "for i in range(n_episode): # 신경망 학습\n",
        "    s,info=env.reset()\n",
        "    length=0\n",
        "    while True:\n",
        "        y_=model.predict(s.reshape([1,s_dim]),verbose=0)[0]\n",
        "        if np.random.random()<eps:\n",
        "            a=np.random.randint(0,a_dim)\n",
        "        else:\n",
        "            a=greedy_select(y_)\n",
        "        s1,r,terminated,truncated,info=env.step(a)\n",
        "        x=s; y=y_\n",
        "        y1_=model.predict(s1.reshape([1,s_dim]),verbose=0)[0]\n",
        "\n",
        "        if terminated:\n",
        "            y[a]=r\n",
        "        else:\n",
        "            y[a]=r+gamma*np.max(y1_)\n",
        "\n",
        "        model.fit(x.reshape([1,s_dim]),y.reshape([1,a_dim]),batch_size=1,epochs=1,verbose=0)\n",
        "\n",
        "        s=s1\n",
        "        length+=1\n",
        "        eps=max(eps_min,eps*eps_decay) # 엡실론 스케줄링\n",
        "\n",
        "        if terminated or truncated:\n",
        "            epi_length.append(length)\n",
        "            break\n",
        "\n",
        "    if np.min(epi_length[-5:])>=env.spec.max_episode_steps: # 연속 5번 최대 길이 넘으면 수렴\n",
        "        break\n",
        "    if (i+1)%10==0:\n",
        "        print(i+1,'번째 에피소드 길이:',np.mean(epi_length[-10:]))\n",
        "\n",
        "# model.save('./f6-2.keras') # 신경망 저장\n",
        "env.close()\n",
        "\n",
        "plt.plot(range(1,len(epi_length)+1),epi_length) # 수렴 곡선 그리기\n",
        "smooth=np.convolve(epi_length,10*[0.1],mode='valid')\n",
        "plt.plot(range(1,len(smooth)+1),smooth)\n",
        "plt.title('Convergence of Q-network for CartPole-v1')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4AhBOZTO2KHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# model = load_model('./f6-2.keras') # 신경망 불러옴\n",
        "\n",
        "env_id = \"CartPole-v1\"\n",
        "\n",
        "# Create a vectorized environment for SB3, specifying the render_mode\n",
        "vec_env = make_vec_env(env_id, n_envs=1, seed=0, wrapper_kwargs={\n",
        "    'render_mode': 'rgb_array'\n",
        "})\n",
        "\n",
        "# env = gym.make(\"CartPole-v1\",render_mode='rgb_array')\n",
        "# s_dim = env.observation_space.shape[0] # 상태 공간 차원\n",
        "\n",
        "# Record the video of the trained agent\n",
        "video_folder = \"videos\"\n",
        "video_length = 500\n",
        "eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "\n",
        "s_dim = eval_env.observation_space.shape[0] # 상태 공간 차원\n",
        "\n",
        "\n",
        "# Wrap the evaluation environment with VecVideoRecorder\n",
        "eval_env = VecVideoRecorder(\n",
        "    eval_env,\n",
        "    video_folder=video_folder,\n",
        "    record_video_trigger=lambda step: step == 0,  # Record only the first episode\n",
        "    video_length=video_length,\n",
        "    name_prefix=f\"ppo-agent-{env_id}\"\n",
        ")\n",
        "\n",
        "length = 0\n",
        "s = eval_env.reset()\n",
        "\n",
        "while True:\n",
        "    q = model.predict(np.reshape(s,[1,s_dim]),verbose=0) # 신경망이 예측한 행동\n",
        "    a = np.argmax(q[0])\n",
        "    s,r,dones,info = eval_env.step(np.array([a])) # Modified: Unpack 4 values and use 'dones'\n",
        "    length += 1\n",
        "\n",
        "    if dones[0]: # Check dones[0] for termination/truncation status of the single environment\n",
        "        print(\"에피소드의 점수:\",length)\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n",
        "# 4. Display the video in Colab\n",
        "show_video(video_folder)\n"
      ],
      "metadata": {
        "id": "wyKI3pBu3Diq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}